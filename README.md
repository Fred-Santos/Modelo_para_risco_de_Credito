# Modelo de Risco de CrÃ©dito â€” ETL e Modelagem com PySpark

Este projeto tem como objetivo **construir um modelo preditivo de risco de crÃ©dito**, abordando desde a etapa de engenharia de dados atÃ© a criaÃ§Ã£o do modelo final.  
O foco principal Ã© estruturar um **pipeline de ETL** utilizando PySpark, consolidar as variÃ¡veis em uma tabela Ãºnica e treinar algoritmos de machine learning para prever o risco de crÃ©dito (*behavior model*).  

---

## ğŸ“Š Fonte dos Dados
Os dados sÃ£o provenientes da competiÃ§Ã£o [Home Credit - Credit Risk Model Stability](https://www.kaggle.com/competitions/home-credit-credit-risk-model-stability/data).  

> âš ï¸ Os datasets **nÃ£o estÃ£o versionados no GitHub** devido ao tamanho (>100MB).  
> Para reproduzir os experimentos, baixe os arquivos pelo Kaggle e extraia-os em `data/raw/`.

---

## ğŸ› ï¸ Etapas do Projeto

### 1. Engenharia de Dados (ETL)
- **Leitura** dos dados brutos com PySpark (`data/raw/`)
- **Limpeza e tratamento**: remoÃ§Ã£o de nulos, normalizaÃ§Ã£o de colunas e casts de tipos
- **Enriquecimento**: criaÃ§Ã£o de novas variÃ¡veis derivadas
- **UnificaÃ§Ã£o** das tabelas em uma estrutura consolidada para treino do modelo

### 2. Modelagem
- ConstruÃ§Ã£o de modelos de classificaÃ§Ã£o para risco de crÃ©dito
- Teste de diferentes algoritmos de ML
- AvaliaÃ§Ã£o de desempenho com mÃ©tricas como **AUC**, **KS**, **precisÃ£o**, **recall** e **F1**

### 3. RelatÃ³rios e DocumentaÃ§Ã£o
- `notebooks/etl_pipeline.ipynb`: orquestra o processo de ETL
- `docs/report.md`: resumo dos experimentos e principais resultados
- `docs/data_dictionary.md`: definiÃ§Ã£o final das variÃ¡veis utilizadas

---

## ğŸ“‚ Estrutura do RepositÃ³rio
```bash
repo/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/        # dados brutos (nÃ£o versionados no GitHub)
â”‚   â”œâ”€â”€ interim/    # dados intermediÃ¡rios
â”‚   â””â”€â”€ processed/  # dados finais prontos para anÃ¡lise/modelagem
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ etl_pipeline.ipynb   # notebook principal do ETL
â”œâ”€â”€ src/
â”‚   â””â”€â”€ etl/        # scripts de apoio (ingestÃ£o, transformaÃ§Ãµes, utils)
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ report.md
â”‚   â””â”€â”€ data_dictionary.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

```

### ğŸš€ Como Rodar Localmente

## Clonar este repositÃ³rio:

git clone https://github.com/Fred-Santos/Modelo_para_risco_de_Credito.git
cd Modelo_para_risco_de_Credito


## Criar um ambiente virtual e instalar dependÃªncias:

python -m venv .venv
.venv\Scripts\activate  # Windows
pip install -r requirements.txt


Baixar os dados no Kaggle e extraÃ­-los em data/raw/.

Iniciar o Jupyter Lab:

jupyter lab


## Executar o notebook principal:

Abra notebooks/etl_pipeline.ipynb

Execute as cÃ©lulas em sequÃªncia para rodar o ETL completo
