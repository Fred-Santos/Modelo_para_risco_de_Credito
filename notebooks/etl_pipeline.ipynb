{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60642a16",
   "metadata": {},
   "source": [
    "# ETL Pipeline (PySpark) — Local\n",
    "Este notebook orquestra leitura (ingest), normalização e transformações simples.\n",
    "Edite os caminhos e funções conforme seu dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a3fd93b-e360-44cc-8b5d-eaf10993a46e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('3.5.3',\n",
       " WindowsPath('C:/Users/fred/meu_projeto_etl/data/raw'),\n",
       " WindowsPath('C:/Users/fred/meu_projeto_etl/data/processed'))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# De notebooks/ sobe 1 nível até a raiz do projeto\n",
    "import sys\n",
    "from pathlib import Path\n",
    "ROOT = Path().resolve().parent\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT))\n",
    "\n",
    "from src.etl.utils import get_spark, RAW, INTERIM, PROCESSED\n",
    "spark = get_spark(\"ETLLocalNotebook\")\n",
    "spark.version, RAW, PROCESSED\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a75bfcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Variable: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      "\n",
      "+-----------------------+--------------------------------------------------+\n",
      "|Variable               |Description                                       |\n",
      "+-----------------------+--------------------------------------------------+\n",
      "|actualdpd_943P         |Days Past Due (DPD) of previous contract (actual).|\n",
      "|actualdpdtolerance_344P|DPD of client with tolerance.                     |\n",
      "|addres_district_368M   |District of the person's address.                 |\n",
      "|addres_role_871L       |Role of person's address.                         |\n",
      "|addres_zip_823M        |Zip code of the address.                          |\n",
      "+-----------------------+--------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- variable: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      "\n",
      "+-----------------------+--------------------------------------------------+\n",
      "|variable               |description                                       |\n",
      "+-----------------------+--------------------------------------------------+\n",
      "|actualdpd_943P         |Days Past Due (DPD) of previous contract (actual).|\n",
      "|actualdpdtolerance_344P|DPD of client with tolerance.                     |\n",
      "|addres_district_368M   |District of the person's address.                 |\n",
      "|addres_role_871L       |Role of person's address.                         |\n",
      "|addres_zip_823M        |Zip code of the address.                          |\n",
      "+-----------------------+--------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ingest: ler todos os CSVs de data/raw\n",
    "from src.etl.ingest import read_csv_folder, basic_normalize\n",
    "df_raw = read_csv_folder(spark, RAW)\n",
    "df_raw.printSchema()\n",
    "df_raw.show(5, truncate=False)\n",
    "\n",
    "# Normalizações básicas\n",
    "df_norm = basic_normalize(df_raw)\n",
    "df_norm.printSchema()\n",
    "df_norm.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2fe875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms: exemplos\n",
    "from src.etl.transform import drop_empty_rows, cast_columns, simple_enrich\n",
    "\n",
    "# Exemplo: defina colunas críticas e casts conforme seu caso\n",
    "critical = []  # ex.: ['id', 'data']\n",
    "casts = {}     # ex.: {'id': 'int', 'valor': 'double'}\n",
    "\n",
    "df_t = drop_empty_rows(df_norm, subset=critical)\n",
    "df_t = cast_columns(df_t, casts)\n",
    "df_t = simple_enrich(df_t)\n",
    "df_t.show(5, truncate=False)\n",
    "df_t.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6f4a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persistência: salva resultado processado em CSV (com header)\n",
    "# Ajuste o caminho/particionamento conforme necessidade.\n",
    "(\n",
    "    df_t.coalesce(1)\n",
    "    .write.mode('overwrite')\n",
    "    .option('header', True)\n",
    "    .csv(str(PROCESSED / 'dataset_processado'))\n",
    ")\n",
    "print('OK — dados salvos em', PROCESSED / 'dataset_processado')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41866b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encerramento opcional da sessão\n",
    "spark.stop()\n",
    "print('SparkSession finalizada')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
